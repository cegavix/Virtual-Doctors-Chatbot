{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "f250c6e44b09489da63445449c3ddb48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ec9fabb1d8db4d399d6abf6cc9c15733",
       "IPY_MODEL_920cdf1bc99c4304abfd3ce136d5ab9a",
       "IPY_MODEL_3e46b8f3838f40258580ef34cce77586"
      ],
      "layout": "IPY_MODEL_5e0ed5db759747739b3ca82651bf80a9"
     }
    },
    "ec9fabb1d8db4d399d6abf6cc9c15733": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88095ebe836b4495b0d8fb7016042428",
      "placeholder": "​",
      "style": "IPY_MODEL_cff71ff4c4874b14bf88ab38b2082791",
      "value": "model.safetensors: 100%"
     }
    },
    "920cdf1bc99c4304abfd3ce136d5ab9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd381dd679ec47f5862c5235d8f44e6e",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3b4c9b5419d84bb0910dd0dbcb745c66",
      "value": 440449768
     }
    },
    "3e46b8f3838f40258580ef34cce77586": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92c20c0ffdbe403abcdec8148ef6588a",
      "placeholder": "​",
      "style": "IPY_MODEL_cf865356a26643938ade56f6130c53c1",
      "value": " 440M/440M [00:06&lt;00:00, 27.5MB/s]"
     }
    },
    "5e0ed5db759747739b3ca82651bf80a9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88095ebe836b4495b0d8fb7016042428": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cff71ff4c4874b14bf88ab38b2082791": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd381dd679ec47f5862c5235d8f44e6e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b4c9b5419d84bb0910dd0dbcb745c66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "92c20c0ffdbe403abcdec8148ef6588a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf865356a26643938ade56f6130c53c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Fine Tune the model BERT with my data.\n",
    "- Takes around 28 minutes with smaller gpt2 version: distilgpt2\n",
    "- Saves to 'output' file\n",
    "- Can be very finnicky with torch environment\n",
    "- Ensure all packages dependencies with transformers are up to date, torch, torch audio etc are up to date."
   ],
   "metadata": {
    "id": "k-J_8Nw-dyYb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Get inputs ready for training"
   ],
   "metadata": {
    "id": "zkAbutJbztCn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizerFast, Trainer, TrainingArguments, EvalPrediction\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "import numpy as np\n",
    "\n",
    "# ! pip install -U accelerate\n",
    "# ! pip install -U transformers\n",
    "\n",
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iE73HFsTOype",
    "outputId": "143f2067-67f8-4283-a173-6c720a8369d7"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open(\"TUSHARKHETE_intents.json\", \"r\") as read_file:\n",
    "    data = (json.load(read_file))['intents']\n",
    "\n",
    "labels = []\n",
    "inputs = []\n",
    "for item in data:\n",
    "   labels.append(item['tag'])\n",
    "   inputs.append(item['patterns'])\n",
    "\n",
    "print(\"We have:\",len(set(labels)),\"labels\")\n",
    "\n",
    "inputs"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "3H8LdTLTRlmJ",
    "outputId": "bc1cd3be-45e5-40de-a7b2-44a11dc037a5"
   },
   "execution_count": 84,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We have: 54 labels\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'],\n",
       " ['What to do if Cuts?',\n",
       "  'How to cure Cuts?',\n",
       "  'Which medicine to apply for Cuts?',\n",
       "  'what to apply on cuts?',\n",
       "  'Cuts'],\n",
       " ['how do you treat abrasions?',\n",
       "  'Do Abrasions cause scars?',\n",
       "  'Abrasions',\n",
       "  'what to do if abrasions?',\n",
       "  'Which medicine to apply for abrasions?',\n",
       "  'How to cure abrasions?'],\n",
       " ['How do you treat Sting?',\n",
       "  'Stings',\n",
       "  'What to do if you get a sting?',\n",
       "  'Which medicine to apply if sting?'],\n",
       " ['How to remove Splinters',\n",
       "  'How to cure Splinters?',\n",
       "  'What to do if I have splinters?',\n",
       "  'How do you bring a splinter to the surface?'],\n",
       " ['How do you treat a sprain?',\n",
       "  'what to do if i get a sprain?',\n",
       "  'Which cream to apply if i get a sprain?',\n",
       "  'Which medicine to apply if I get a sprain?'],\n",
       " ['How do you treat a strain?',\n",
       "  'what to do if i get a strain?',\n",
       "  'Which cream to apply if i get a strain?',\n",
       "  'Which medicine to apply if I get a strain?',\n",
       "  'How do you diagnose a strain?',\n",
       "  'Is heat or ice better for a pulled muscle?'],\n",
       " ['How do you treat a mild Fever?',\n",
       "  'what to do if i get a mild fever?',\n",
       "  'Which medicine to take if I get a mild fever?',\n",
       "  'fever'],\n",
       " ['How do you treat nasal Congestion?',\n",
       "  'what to do if i get a nasal congestion?',\n",
       "  'Which medicine to take if I have a nasal congestion?',\n",
       "  'what to do if i have a blocked nose?',\n",
       "  'How do you treat a blocked nose?',\n",
       "  'How long does nasal congestion last?'],\n",
       " ['How to cure cough?',\n",
       "  'How do you treat cough?',\n",
       "  'what to do if i get a cough?',\n",
       "  'Which medicine to take if I get cough?',\n",
       "  'How do you get rid of cough?'],\n",
       " ['How do you treat sore throat?',\n",
       "  'what to do if i get a sore throat?',\n",
       "  'Which medicine to take if I get a sore throat?',\n",
       "  'How to cure sore throat?'],\n",
       " ['How do you treat gas problems?',\n",
       "  'what to do if i have Gastrointestinal problems?',\n",
       "  'Which medicine to take if I get gas problem?',\n",
       "  'How to cure Gas problems?'],\n",
       " ['How do you treat Skin problems?',\n",
       "  'what to do if i get a skin allergy?',\n",
       "  'Which medicine to take if I get a skin allergy?',\n",
       "  'How to cure skin allergy?'],\n",
       " ['What are the symptoms of chickenpox?',\n",
       "  'How contagious is chickenpox?',\n",
       "  'How long does chickenpox last?',\n",
       "  'How to treat chickenpox at home?'],\n",
       " ['What are the common symptoms of allergies?',\n",
       "  'What are some triggers for allergies?',\n",
       "  \"How can I identify what I'm allergic to?\",\n",
       "  'How to treat allergies?'],\n",
       " ['How do you treat Abdonominal Pain?',\n",
       "  'what to do if i get a Abdonominal Pain?',\n",
       "  'Which medicine to take if I get a Abdonominal Pain?',\n",
       "  'How to cure Abdonominal Pain?'],\n",
       " ['How do you treat Bruises?',\n",
       "  'what to do if i get a Bruise?',\n",
       "  'Which medicine to take if I get a Bruise?',\n",
       "  'How to cure Bruises?'],\n",
       " ['How do you treat a Broken Toe?',\n",
       "  'what to do if i get a Broken Toe?',\n",
       "  'Which medicine to take if I get a Broken Toe?',\n",
       "  'How to cure Broken Toe?'],\n",
       " ['How do you treat Choking?',\n",
       "  'what to do if i get a Choke?',\n",
       "  'Which medicine to take if I get Choked?',\n",
       "  'How to cure Choking?'],\n",
       " ['How do you treat a wound?',\n",
       "  'what to do if i get a Wound?',\n",
       "  'Which medicine to take if I get wounded?',\n",
       "  'How to cure a wound?'],\n",
       " ['How do you treat Diarrhea?',\n",
       "  'what to do if i get Diarrhea?',\n",
       "  'Which medicine to take if I get Diarrhea?',\n",
       "  'How to cure Diarrhea?'],\n",
       " ['How do you treat a Frost bite?',\n",
       "  'what to do if i get a Frost bite?',\n",
       "  'Which medicine to take if I get a Frost bite?',\n",
       "  'How to cure Frost bite?'],\n",
       " ['How do you treat Heat Exhaustion?',\n",
       "  'what to do if i feel Exhausted due to heat?',\n",
       "  'Which medicine to take if I get Exhausted?',\n",
       "  'How to cure Heat Exhaustion?'],\n",
       " ['How do you treat Heat Stroke?',\n",
       "  'what to do if i get a Heat Stroke?',\n",
       "  'Which medicine to take if I get Stroke?',\n",
       "  'How to cure a Heat Stroke?'],\n",
       " ['How do you treat a Insect Bite?',\n",
       "  'what to do if a insect bites me?',\n",
       "  'Which medicine to take if I get bitten by a insect?',\n",
       "  'How to cure insect bite?'],\n",
       " ['How do you treat a bleeding nose?',\n",
       "  'what to do if i my nose is bleeding?',\n",
       "  'Which medicine to take if I get nose bleed?',\n",
       "  'How to cure nose bleeding?'],\n",
       " ['How do you treat a Pulled Muscle?',\n",
       "  'what to do if my muscle is pulled?',\n",
       "  'Which medicine to take if I got pulled muscle?',\n",
       "  'How to cure a pulled muscle?'],\n",
       " ['How do you treat Rectal Bleeding?',\n",
       "  'what to do if i get a Rectal Bleeding?',\n",
       "  'Which medicine to take if I get Rectal Bleeding?',\n",
       "  'How to cure Rectal Bleeding?'],\n",
       " ['How do you treat Sun Burn?',\n",
       "  'what to do if i get a Sun Burn?',\n",
       "  'Which medicine to take if I get Sun Burn?',\n",
       "  'How to cure a Sun Burn?'],\n",
       " ['How do you treat Testicle Pain?',\n",
       "  'what to do if i get a Testicle Pain?',\n",
       "  'Which medicine to take if I get a Testicle Pain?',\n",
       "  'How to cure Testicle Pain?'],\n",
       " ['How do you treat a Vertigo?',\n",
       "  'what to do if i get a Vertigo?',\n",
       "  'Which medicine to take if I get Vertigo?',\n",
       "  'How to cure a Vertigo?'],\n",
       " ['How do you treat bleeding?',\n",
       "  'what to do if i get a Bleeding?',\n",
       "  'Which medicine to take if I get bleeding?',\n",
       "  'How to cure Bleeding?'],\n",
       " ['How do you treat an eye Injury?',\n",
       "  'what to do if i get a eye Injury?',\n",
       "  'Which medicine to take if I injured my eye?',\n",
       "  'How to cure injured eye?'],\n",
       " ['How do you treat a chemical burn?',\n",
       "  'what to do if i get a Chemical Burn?',\n",
       "  'Which medicine to take if I get burn due to chemicals?',\n",
       "  'How to cure Chemical Burn?'],\n",
       " ['How do you treat a Poison?',\n",
       "  'what to do if i get Poison?',\n",
       "  'Which medicine to take if I am poisoned?',\n",
       "  'How to cure Poisoning?'],\n",
       " ['How do you treat broken Teeth ?',\n",
       "  'what to do if my Teeth got broken?',\n",
       "  'Which medicine to take if I get broken teeth?',\n",
       "  'cure broken teeth?'],\n",
       " ['How do you treat a seizure?',\n",
       "  'what to do if i get a seizure?',\n",
       "  'Which medicine to take if I get seizure?',\n",
       "  'How to cure seizure?'],\n",
       " ['How do you treat a head Injury?',\n",
       "  'what to do if i get a Head Injury?',\n",
       "  'Which medicine to take if I get injured in the head?',\n",
       "  'How to cure Head Injury?'],\n",
       " ['How do you treat Faint?',\n",
       "  'what to do if i feel like Fainting?',\n",
       "  'Which medicine to take if I get a Faint?',\n",
       "  'How to cure Fainting?'],\n",
       " ['How do you treat a mild Headache?',\n",
       "  'what to do if i get a mild Headache?',\n",
       "  'Which medicine to take if I have a mild headache?',\n",
       "  'How to cure a mild headache?'],\n",
       " ['How do you treat a Cold?',\n",
       "  'what to do if i get a mild Cold?',\n",
       "  'Which medicine to take if I have a Cold?',\n",
       "  'How to cure Cold?'],\n",
       " ['How do you treat Rashes?',\n",
       "  'what to do if i get a Rash?',\n",
       "  'Which medicine to take if I have a Rash?',\n",
       "  'How to cure Rash?'],\n",
       " ['How do you treat a snake bite?',\n",
       "  'what to do if i get a snake bite?',\n",
       "  'Which medicine to take if I get a snake bite?',\n",
       "  'How to cure snake bite?',\n",
       "  'i got bit by a snake'],\n",
       " ['How do you treat a animal bite?',\n",
       "  'How do you treat a monkey bite?',\n",
       "  'How do you treat a dog bite?',\n",
       "  'what to do if i get a animal bite?',\n",
       "  'Which medicine to take if I get a monekey bite?',\n",
       "  'How to cure dog bite?',\n",
       "  'i got bit by a dog'],\n",
       " ['What to do if someone is Drowning?',\n",
       "  'what to do if someone drowned?',\n",
       "  'What steps to take if i see a drowning person?',\n",
       "  'How to help a drowning person?'],\n",
       " ['How to give CPR??',\n",
       "  'what to do in a CPR?',\n",
       "  'What steps to take in a CPR??',\n",
       "  'How to help a drowning person in CPR?'],\n",
       " ['How do you treat a Fracture?',\n",
       "  'what to do if i get a Fracture?',\n",
       "  'Which medicine to take if I have a Fracture?',\n",
       "  'How to cure a Fracture?'],\n",
       " ['What is Anxiety',\n",
       "  'How do I know if I have anxiety disorder',\n",
       "  'How would I know when to visit a therapist for help for my anxiety',\n",
       "  'Is anxiety normal, what is the line where you should go seek help'],\n",
       " [\"How do I know if I'm depressed\",\n",
       "  \"What is depression, how to know if you're depressed\",\n",
       "  'What are the symptoms to depression',\n",
       "  'What is depression, How does it affect people',\n",
       "  'How is depression affecting my daily life routine'],\n",
       " ['I want you diagnose my illness',\n",
       "  'Can you diagnose me',\n",
       "  'Which medicine to take if I have ?',\n",
       "  'I need a real diagnosis',\n",
       "  'Can you tell me what illness I have',\n",
       "  'I want to give you my symptoms'],\n",
       " ['What is Neutrino about?',\n",
       "  'What do you do?',\n",
       "  'Who are you, what do you do?',\n",
       "  'Who am I talking to, who are you',\n",
       "  'Tell me what to do',\n",
       "  'Help me, how i use this'],\n",
       " ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\", 'Cheers'],\n",
       " ['can I make an appointment',\n",
       "  'where can I make an appointment',\n",
       "  'how can I schedule an appointment',\n",
       "  \"I'd like to book an appointment\",\n",
       "  'Do you have any appointments available',\n",
       "  'Is it possible to see a doctor today'],\n",
       " ['Bye', 'See you later', 'Goodbye', \"I'm going now\", 'Goodnight']]"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "inputs_new = []\n",
    "labels_new = []\n",
    "\n",
    "for sentence_list, label in zip(inputs, labels):\n",
    "  for sentence in sentence_list:\n",
    "    inputs_new.append(sentence)\n",
    "    labels_new.append(label)\n",
    "\n",
    "print(labels_new)\n",
    "print(inputs_new)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73GldPvyZY5W",
    "outputId": "44d323d0-d859-4d39-fb36-67e8e551d81e"
   },
   "execution_count": 92,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'Cuts', 'Cuts', 'Cuts', 'Cuts', 'Cuts', 'Abrasions', 'Abrasions', 'Abrasions', 'Abrasions', 'Abrasions', 'Abrasions', 'stings', 'stings', 'stings', 'stings', 'Splinter', 'Splinter', 'Splinter', 'Splinter', 'Sprains', 'Sprains', 'Sprains', 'Sprains', 'Strains', 'Strains', 'Strains', 'Strains', 'Strains', 'Strains', 'Fever', 'Fever', 'Fever', 'Fever', 'Nasal Congestion', 'Nasal Congestion', 'Nasal Congestion', 'Nasal Congestion', 'Nasal Congestion', 'Nasal Congestion', 'Cough', 'Cough', 'Cough', 'Cough', 'Cough', 'Sore Throat', 'Sore Throat', 'Sore Throat', 'Sore Throat', 'Gastrointestinal problems', 'Gastrointestinal problems', 'Gastrointestinal problems', 'Gastrointestinal problems', 'Skin problems', 'Skin problems', 'Skin problems', 'Skin problems', 'Chickenpox', 'Chickenpox', 'Chickenpox', 'Chickenpox', 'Allergies', 'Allergies', 'Allergies', 'Allergies', 'Abdonominal Pain', 'Abdonominal Pain', 'Abdonominal Pain', 'Abdonominal Pain', 'Bruises', 'Bruises', 'Bruises', 'Bruises', 'Broken Toe', 'Broken Toe', 'Broken Toe', 'Broken Toe', 'Choking', 'Choking', 'Choking', 'Choking', 'Wound', 'Wound', 'Wound', 'Wound', 'Diarrhea', 'Diarrhea', 'Diarrhea', 'Diarrhea', 'Frost bite', 'Frost bite', 'Frost bite', 'Frost bite', 'Heat Exhaustion', 'Heat Exhaustion', 'Heat Exhaustion', 'Heat Exhaustion', 'Heat Stroke', 'Heat Stroke', 'Heat Stroke', 'Heat Stroke', 'Insect Bites', 'Insect Bites', 'Insect Bites', 'Insect Bites', 'nose bleed', 'nose bleed', 'nose bleed', 'nose bleed', 'Pulled Muscle', 'Pulled Muscle', 'Pulled Muscle', 'Pulled Muscle', 'Rectal bleeding', 'Rectal bleeding', 'Rectal bleeding', 'Rectal bleeding', 'Sun Burn', 'Sun Burn', 'Sun Burn', 'Sun Burn', 'Testicle Pain', 'Testicle Pain', 'Testicle Pain', 'Testicle Pain', 'Vertigo', 'Vertigo', 'Vertigo', 'Vertigo', 'Normal Bleeding', 'Normal Bleeding', 'Normal Bleeding', 'Normal Bleeding', 'Eye Injury', 'Eye Injury', 'Eye Injury', 'Eye Injury', 'Chemical Burn', 'Chemical Burn', 'Chemical Burn', 'Chemical Burn', 'Poison', 'Poison', 'Poison', 'Poison', 'Teeth', 'Teeth', 'Teeth', 'Teeth', 'seizure', 'seizure', 'seizure', 'seizure', 'Head Injury', 'Head Injury', 'Head Injury', 'Head Injury', 'Fainting', 'Fainting', 'Fainting', 'Fainting', 'Headache', 'Headache', 'Headache', 'Headache', 'Cold', 'Cold', 'Cold', 'Cold', 'Rash', 'Rash', 'Rash', 'Rash', 'snake bite', 'snake bite', 'snake bite', 'snake bite', 'snake bite', 'animal bite', 'animal bite', 'animal bite', 'animal bite', 'animal bite', 'animal bite', 'animal bite', 'Drowning', 'Drowning', 'Drowning', 'Drowning', 'CPR', 'CPR', 'CPR', 'CPR', 'Fracture', 'Fracture', 'Fracture', 'Fracture', 'Anxiety', 'Anxiety', 'Anxiety', 'Anxiety', 'Depression', 'Depression', 'Depression', 'Depression', 'Depression', 'Symptoms', 'Symptoms', 'Symptoms', 'Symptoms', 'Symptoms', 'Symptoms', 'about', 'about', 'about', 'about', 'about', 'about', 'thanks', 'thanks', 'thanks', 'thanks', 'thanks', 'Appointment', 'Appointment', 'Appointment', 'Appointment', 'Appointment', 'Appointment', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye']\n",
      "['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day', 'What to do if Cuts?', 'How to cure Cuts?', 'Which medicine to apply for Cuts?', 'what to apply on cuts?', 'Cuts', 'how do you treat abrasions?', 'Do Abrasions cause scars?', 'Abrasions', 'what to do if abrasions?', 'Which medicine to apply for abrasions?', 'How to cure abrasions?', 'How do you treat Sting?', 'Stings', 'What to do if you get a sting?', 'Which medicine to apply if sting?', 'How to remove Splinters', 'How to cure Splinters?', 'What to do if I have splinters?', 'How do you bring a splinter to the surface?', 'How do you treat a sprain?', 'what to do if i get a sprain?', 'Which cream to apply if i get a sprain?', 'Which medicine to apply if I get a sprain?', 'How do you treat a strain?', 'what to do if i get a strain?', 'Which cream to apply if i get a strain?', 'Which medicine to apply if I get a strain?', 'How do you diagnose a strain?', 'Is heat or ice better for a pulled muscle?', 'How do you treat a mild Fever?', 'what to do if i get a mild fever?', 'Which medicine to take if I get a mild fever?', 'fever', 'How do you treat nasal Congestion?', 'what to do if i get a nasal congestion?', 'Which medicine to take if I have a nasal congestion?', 'what to do if i have a blocked nose?', 'How do you treat a blocked nose?', 'How long does nasal congestion last?', 'How to cure cough?', 'How do you treat cough?', 'what to do if i get a cough?', 'Which medicine to take if I get cough?', 'How do you get rid of cough?', 'How do you treat sore throat?', 'what to do if i get a sore throat?', 'Which medicine to take if I get a sore throat?', 'How to cure sore throat?', 'How do you treat gas problems?', 'what to do if i have Gastrointestinal problems?', 'Which medicine to take if I get gas problem?', 'How to cure Gas problems?', 'How do you treat Skin problems?', 'what to do if i get a skin allergy?', 'Which medicine to take if I get a skin allergy?', 'How to cure skin allergy?', 'What are the symptoms of chickenpox?', 'How contagious is chickenpox?', 'How long does chickenpox last?', 'How to treat chickenpox at home?', 'What are the common symptoms of allergies?', 'What are some triggers for allergies?', \"How can I identify what I'm allergic to?\", 'How to treat allergies?', 'How do you treat Abdonominal Pain?', 'what to do if i get a Abdonominal Pain?', 'Which medicine to take if I get a Abdonominal Pain?', 'How to cure Abdonominal Pain?', 'How do you treat Bruises?', 'what to do if i get a Bruise?', 'Which medicine to take if I get a Bruise?', 'How to cure Bruises?', 'How do you treat a Broken Toe?', 'what to do if i get a Broken Toe?', 'Which medicine to take if I get a Broken Toe?', 'How to cure Broken Toe?', 'How do you treat Choking?', 'what to do if i get a Choke?', 'Which medicine to take if I get Choked?', 'How to cure Choking?', 'How do you treat a wound?', 'what to do if i get a Wound?', 'Which medicine to take if I get wounded?', 'How to cure a wound?', 'How do you treat Diarrhea?', 'what to do if i get Diarrhea?', 'Which medicine to take if I get Diarrhea?', 'How to cure Diarrhea?', 'How do you treat a Frost bite?', 'what to do if i get a Frost bite?', 'Which medicine to take if I get a Frost bite?', 'How to cure Frost bite?', 'How do you treat Heat Exhaustion?', 'what to do if i feel Exhausted due to heat?', 'Which medicine to take if I get Exhausted?', 'How to cure Heat Exhaustion?', 'How do you treat Heat Stroke?', 'what to do if i get a Heat Stroke?', 'Which medicine to take if I get Stroke?', 'How to cure a Heat Stroke?', 'How do you treat a Insect Bite?', 'what to do if a insect bites me?', 'Which medicine to take if I get bitten by a insect?', 'How to cure insect bite?', 'How do you treat a bleeding nose?', 'what to do if i my nose is bleeding?', 'Which medicine to take if I get nose bleed?', 'How to cure nose bleeding?', 'How do you treat a Pulled Muscle?', 'what to do if my muscle is pulled?', 'Which medicine to take if I got pulled muscle?', 'How to cure a pulled muscle?', 'How do you treat Rectal Bleeding?', 'what to do if i get a Rectal Bleeding?', 'Which medicine to take if I get Rectal Bleeding?', 'How to cure Rectal Bleeding?', 'How do you treat Sun Burn?', 'what to do if i get a Sun Burn?', 'Which medicine to take if I get Sun Burn?', 'How to cure a Sun Burn?', 'How do you treat Testicle Pain?', 'what to do if i get a Testicle Pain?', 'Which medicine to take if I get a Testicle Pain?', 'How to cure Testicle Pain?', 'How do you treat a Vertigo?', 'what to do if i get a Vertigo?', 'Which medicine to take if I get Vertigo?', 'How to cure a Vertigo?', 'How do you treat bleeding?', 'what to do if i get a Bleeding?', 'Which medicine to take if I get bleeding?', 'How to cure Bleeding?', 'How do you treat an eye Injury?', 'what to do if i get a eye Injury?', 'Which medicine to take if I injured my eye?', 'How to cure injured eye?', 'How do you treat a chemical burn?', 'what to do if i get a Chemical Burn?', 'Which medicine to take if I get burn due to chemicals?', 'How to cure Chemical Burn?', 'How do you treat a Poison?', 'what to do if i get Poison?', 'Which medicine to take if I am poisoned?', 'How to cure Poisoning?', 'How do you treat broken Teeth ?', 'what to do if my Teeth got broken?', 'Which medicine to take if I get broken teeth?', 'cure broken teeth?', 'How do you treat a seizure?', 'what to do if i get a seizure?', 'Which medicine to take if I get seizure?', 'How to cure seizure?', 'How do you treat a head Injury?', 'what to do if i get a Head Injury?', 'Which medicine to take if I get injured in the head?', 'How to cure Head Injury?', 'How do you treat Faint?', 'what to do if i feel like Fainting?', 'Which medicine to take if I get a Faint?', 'How to cure Fainting?', 'How do you treat a mild Headache?', 'what to do if i get a mild Headache?', 'Which medicine to take if I have a mild headache?', 'How to cure a mild headache?', 'How do you treat a Cold?', 'what to do if i get a mild Cold?', 'Which medicine to take if I have a Cold?', 'How to cure Cold?', 'How do you treat Rashes?', 'what to do if i get a Rash?', 'Which medicine to take if I have a Rash?', 'How to cure Rash?', 'How do you treat a snake bite?', 'what to do if i get a snake bite?', 'Which medicine to take if I get a snake bite?', 'How to cure snake bite?', 'i got bit by a snake', 'How do you treat a animal bite?', 'How do you treat a monkey bite?', 'How do you treat a dog bite?', 'what to do if i get a animal bite?', 'Which medicine to take if I get a monekey bite?', 'How to cure dog bite?', 'i got bit by a dog', 'What to do if someone is Drowning?', 'what to do if someone drowned?', 'What steps to take if i see a drowning person?', 'How to help a drowning person?', 'How to give CPR??', 'what to do in a CPR?', 'What steps to take in a CPR??', 'How to help a drowning person in CPR?', 'How do you treat a Fracture?', 'what to do if i get a Fracture?', 'Which medicine to take if I have a Fracture?', 'How to cure a Fracture?', 'What is Anxiety', 'How do I know if I have anxiety disorder', 'How would I know when to visit a therapist for help for my anxiety', 'Is anxiety normal, what is the line where you should go seek help', \"How do I know if I'm depressed\", \"What is depression, how to know if you're depressed\", 'What are the symptoms to depression', 'What is depression, How does it affect people', 'How is depression affecting my daily life routine', 'I want you diagnose my illness', 'Can you diagnose me', 'Which medicine to take if I have ?', 'I need a real diagnosis', 'Can you tell me what illness I have', 'I want to give you my symptoms', 'What is Neutrino about?', 'What do you do?', 'Who are you, what do you do?', 'Who am I talking to, who are you', 'Tell me what to do', 'Help me, how i use this', 'Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\", 'Cheers', 'can I make an appointment', 'where can I make an appointment', 'how can I schedule an appointment', \"I'd like to book an appointment\", 'Do you have any appointments available', 'Is it possible to see a doctor today', 'Bye', 'See you later', 'Goodbye', \"I'm going now\", 'Goodnight']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Encode the labels\n",
    "So that the model can use them (string not accepted)"
   ],
   "metadata": {
    "id": "KLo6HpYnYjPt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "print(\"Before encoding:\",labels_new)\n",
    "# Encode the labels (text to numbers). NEED THIS FOR evaluation SO REMEMBER TO PICKLE\n",
    "labels_new = label_encoder.fit_transform(labels_new)\n",
    "(print(\"after encoding:\", labels_new))\n",
    "\n",
    "import pickle\n",
    "# Save the label encoder\n",
    "try:\n",
    "    with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "        pickle.dump(label_encoder, f)\n",
    "except Exception as e:\n",
    "    print(\"Error saving pickle file:\", e)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "j4CHNrLKYp23",
    "outputId": "646ec32e-e242-4846-df8d-4c8335b52661"
   },
   "execution_count": 93,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before encoding: ['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'Cuts', 'Cuts', 'Cuts', 'Cuts', 'Cuts', 'Abrasions', 'Abrasions', 'Abrasions', 'Abrasions', 'Abrasions', 'Abrasions', 'stings', 'stings', 'stings', 'stings', 'Splinter', 'Splinter', 'Splinter', 'Splinter', 'Sprains', 'Sprains', 'Sprains', 'Sprains', 'Strains', 'Strains', 'Strains', 'Strains', 'Strains', 'Strains', 'Fever', 'Fever', 'Fever', 'Fever', 'Nasal Congestion', 'Nasal Congestion', 'Nasal Congestion', 'Nasal Congestion', 'Nasal Congestion', 'Nasal Congestion', 'Cough', 'Cough', 'Cough', 'Cough', 'Cough', 'Sore Throat', 'Sore Throat', 'Sore Throat', 'Sore Throat', 'Gastrointestinal problems', 'Gastrointestinal problems', 'Gastrointestinal problems', 'Gastrointestinal problems', 'Skin problems', 'Skin problems', 'Skin problems', 'Skin problems', 'Chickenpox', 'Chickenpox', 'Chickenpox', 'Chickenpox', 'Allergies', 'Allergies', 'Allergies', 'Allergies', 'Abdonominal Pain', 'Abdonominal Pain', 'Abdonominal Pain', 'Abdonominal Pain', 'Bruises', 'Bruises', 'Bruises', 'Bruises', 'Broken Toe', 'Broken Toe', 'Broken Toe', 'Broken Toe', 'Choking', 'Choking', 'Choking', 'Choking', 'Wound', 'Wound', 'Wound', 'Wound', 'Diarrhea', 'Diarrhea', 'Diarrhea', 'Diarrhea', 'Frost bite', 'Frost bite', 'Frost bite', 'Frost bite', 'Heat Exhaustion', 'Heat Exhaustion', 'Heat Exhaustion', 'Heat Exhaustion', 'Heat Stroke', 'Heat Stroke', 'Heat Stroke', 'Heat Stroke', 'Insect Bites', 'Insect Bites', 'Insect Bites', 'Insect Bites', 'nose bleed', 'nose bleed', 'nose bleed', 'nose bleed', 'Pulled Muscle', 'Pulled Muscle', 'Pulled Muscle', 'Pulled Muscle', 'Rectal bleeding', 'Rectal bleeding', 'Rectal bleeding', 'Rectal bleeding', 'Sun Burn', 'Sun Burn', 'Sun Burn', 'Sun Burn', 'Testicle Pain', 'Testicle Pain', 'Testicle Pain', 'Testicle Pain', 'Vertigo', 'Vertigo', 'Vertigo', 'Vertigo', 'Normal Bleeding', 'Normal Bleeding', 'Normal Bleeding', 'Normal Bleeding', 'Eye Injury', 'Eye Injury', 'Eye Injury', 'Eye Injury', 'Chemical Burn', 'Chemical Burn', 'Chemical Burn', 'Chemical Burn', 'Poison', 'Poison', 'Poison', 'Poison', 'Teeth', 'Teeth', 'Teeth', 'Teeth', 'seizure', 'seizure', 'seizure', 'seizure', 'Head Injury', 'Head Injury', 'Head Injury', 'Head Injury', 'Fainting', 'Fainting', 'Fainting', 'Fainting', 'Headache', 'Headache', 'Headache', 'Headache', 'Cold', 'Cold', 'Cold', 'Cold', 'Rash', 'Rash', 'Rash', 'Rash', 'snake bite', 'snake bite', 'snake bite', 'snake bite', 'snake bite', 'animal bite', 'animal bite', 'animal bite', 'animal bite', 'animal bite', 'animal bite', 'animal bite', 'Drowning', 'Drowning', 'Drowning', 'Drowning', 'CPR', 'CPR', 'CPR', 'CPR', 'Fracture', 'Fracture', 'Fracture', 'Fracture', 'Anxiety', 'Anxiety', 'Anxiety', 'Anxiety', 'Depression', 'Depression', 'Depression', 'Depression', 'Depression', 'Symptoms', 'Symptoms', 'Symptoms', 'Symptoms', 'Symptoms', 'Symptoms', 'about', 'about', 'about', 'about', 'about', 'about', 'thanks', 'thanks', 'thanks', 'thanks', 'thanks', 'Appointment', 'Appointment', 'Appointment', 'Appointment', 'Appointment', 'Appointment', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye']\n",
      "after encoding: [48 48 48 48 48 48 13 13 13 13 13  1  1  1  1  1  1 52 52 52 52 36 36 36\n",
      " 36 37 37 37 37 38 38 38 38 38 38 19 19 19 19 28 28 28 28 28 28 12 12 12\n",
      " 12 12 35 35 35 35 22 22 22 22 34 34 34 34  9  9  9  9  2  2  2  2  0  0\n",
      "  0  0  6  6  6  6  5  5  5  5 10 10 10 10 44 44 44 44 15 15 15 15 21 21\n",
      " 21 21 25 25 25 25 26 26 26 26 27 27 27 27 49 49 49 49 31 31 31 31 33 33\n",
      " 33 33 39 39 39 39 42 42 42 42 43 43 43 43 29 29 29 29 17 17 17 17  8  8\n",
      "  8  8 30 30 30 30 41 41 41 41 50 50 50 50 23 23 23 23 18 18 18 18 24 24\n",
      " 24 24 11 11 11 11 32 32 32 32 51 51 51 51 51 46 46 46 46 46 46 46 16 16\n",
      " 16 16  7  7  7  7 20 20 20 20  3  3  3  3 14 14 14 14 14 40 40 40 40 40\n",
      " 40 45 45 45 45 45 45 53 53 53 53 53  4  4  4  4  4  4 47 47 47 47 47]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# testing_data = ['Hey how are you','How to clean cuts?','how to treat abrasion?',\n",
    "#                 'what medicine for a sting?','i have splinters', 'what to do if i get a sprain', \"what to do if i get a strain\",\n",
    "#                 \"what to do if i get a high fever?\", \"How do you treat nasal Congestio\",\n",
    "#                 \"what to do if i get a cough?\",\"what to do if i get a sore throat?\",\n",
    "#                 \"I have some gas problems\",\"what to do get a skin allergy?\",\n",
    "#                 \"How contagious is chickenpox\",\"what are the symptoms of allergies\",\n",
    "#                 \"Which medicine to take if I get a Abdonominal Pain?\",\"what to do if i get a Bruise?\",\n",
    "#                 \"what to do if i have a Broken Toe?\",\"How do you treat Choking?\",\"how to treat a wound\",\n",
    "#                 \"i've had bad diarrhea\",'how to treat frost bite?',\n",
    "#                 \" treat heat exhaustion?\", \"how do u treat heat stroke?\",\n",
    "#                 \"how do you treat insect bites?\",\"how do you treat a nose bleed?\",\n",
    "#                 \"how do you treat a pulled muscle?\",\"what is rectal bleeding?\",\n",
    "#                 \"sunburn treatment?\",\"what is testicle pain\",\"how to treat vertigo\",\n",
    "#                 \"what to treat bleeding\",\"my eye is injured how do i treat it\",\n",
    "#                 \"chemical burn treatment?\",\"what is poison treatment\",\"what to do if my teeth broke\",\"i'm having a seizure how to cure\",\"how to treat head injuries?\",\"i keep fainting, how to cure fainting?\",\"how to treat a mild headache?\",\"howto treat a cold?\",\"how should i treat a rash\",\"How should i treat a snake bite\",\"ive got an animal bite\",\"what to do if someone is drowning\",\"How to do CPR\",\"how to treat fracture on someone\",\"anxiety i think i have it\",\"how doi know if im depressed\",\"i want you to diagnose my symptoms for me\",\"what is neutrino about?\",\"Thank you!\",\"Can i make an appointment please\",\"bYE BYE!!\"]\n",
    "# testing_data2 = ['good morning','ive got a bad cut what do i do?','how do you treat abrasion? its painful',\n",
    "#                 'what medicine should i take for a sting?','i have splinters, help!', 'what to do if i get a ankle sprain', \"what to do if i get a strain in my muscle\",\n",
    "#                 \"what to do if i get a high fever?\", \"I've had bad nasal congestions for the past week\",\n",
    "#                 \"how do i ease a cough?\",\"I need medicine for a sore throat\",\n",
    "#                 \"I have some gas problems\",\"what to do get a skin allergy?\",\n",
    "#                 \"How contagious is chickenpox\",\"i have pretty bad allergies\",\n",
    "#                 \"I got Pain in my abdomen\",\"what to do if i get a Bruise?\",\n",
    "#                 \"what to do if i have Broken my Toe?\",\"How do you treat Choking emergency?\",\"I have a wound\",\n",
    "#                 \"what to do if i get diarrhea\",'how to treat frost bite?',\n",
    "#                 \" help me treat heat exhaustion?\", \"I have heat stroke\",\n",
    "#                 \"how do you treat insect bites?\",\"how do you treat a nose bleed?\",\n",
    "#                 \"how do you treat a pulled muscle?\",\"i have rectal bleeding?\",\n",
    "#                 \"sunburn treatment im feeling hot?\",\"I think i have testicular torsion\",\"i've had vertigo\",\n",
    "#                 \"how to stop bleeding\",\"my eye is injured how do i treat it\",\n",
    "#                 \"chemical burn treatment?\",\"what is poison treatment\",\"i broke a tooth\",\"i always have seizures, how to stop them\",\"how to treat head injuries?\",\"i keep fainting, how to cure fainting?\",\"how to treat a mild headache?\",\"howto treat a cold?\",\"how should i treat a rash\",\"How should i treat a snake bite\",\"ive got an animal bite\",\"what to do if someone is drowning\",\"How to do CPR\",\"how to treat fracture on someone\",\"anxiety i think i have it\",\"how doi know if im depressed\",\"i want you to diagnose my symptoms for me\",\"what is neutrino about?\",\"Thank you!\",\"Can i make an appointment please\",\"bYE BYE!!\"]\n",
    "\n",
    "# testing_data = np.asarray(testing_data)\n",
    "# # with open('label_encoder.pkl', 'rb') as f:\n",
    "# #     label_encoder = pickle.load(f)\n",
    "\n",
    "# testing_labels = label_encoder.transform(labels)\n",
    "# testing_data = np.append(testing_data,testing_data2)\n",
    "# testing_labels = np.append(testing_labels,testing_labels)\n",
    "\n",
    "# testing_labels"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "NTJJZLKEZX-V",
    "outputId": "f2a329fa-5648-4fc8-b8a8-77473a93db56"
   },
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "error",
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mEOFError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-49-191b510d2a8a>\u001B[0m in \u001B[0;36m<cell line: 33>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[0mtesting_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtesting_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'label_encoder.pkl'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 34\u001B[0;31m     \u001B[0mlabel_encoder\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     35\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[0mtesting_labels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabel_encoder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mEOFError\u001B[0m: Ran out of input"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer, AdamW\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in inputs_new:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', inputs_new[2])\n",
    "print('Token IDs:', input_ids[2])\n",
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "SkAukSTZXnjo",
    "outputId": "c9dc0500-ea89-46c0-ccef-e67aac0dc789"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original:  How are you\n",
      "Token IDs: [101, 2129, 2024, 2017, 102]\n",
      "Max sentence length:  16\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "MAX_LEN = 16\n",
    "\n",
    "#Padding the input to the max length that is 16\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
    "                          value=0, truncating=\"post\", padding=\"post\")"
   ],
   "metadata": {
    "id": "UgdpchKDo0Nr"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Creating the attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids:\n",
    "\n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "\n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)\n",
    "\n",
    "len(input_ids)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ynLrm9rEpHPX",
    "outputId": "e8a0a5d6-3b6b-4698-bbeb-b727299bdf4c"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Split data and assign to trainer"
   ],
   "metadata": {
    "id": "MYnykd9IUJ44"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets (adjust test_size as needed)\n",
    "train_inputs, input_val,validation_inputs, validation_labels = train_test_split(input_ids,labels_new, test_size=0.25, random_state=42)\n",
    "train_masks, validation_masks,_, _ = train_test_split(attention_masks, labels_new,random_state=42, test_size=0.25)\n"
   ],
   "metadata": {
    "id": "-hoI-vyiTkni"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Converting the input data to the tensor , which can be feeded to the model\n",
    "train_inputs = torch.tensor(input_train)\n",
    "validation_inputs = torch.tensor(input_val)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n"
   ],
   "metadata": {
    "collapsed": true,
    "id": "lmnbBcEcc2fh"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = RandomSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ],
   "metadata": {
    "id": "ywJnfGERwVTp"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "from transformers import BertTokenizer, AdamW\n",
    "#Creating the DataLoader which will help us to load data into the CPU in my case\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels = 54,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False, )\n",
    "\n",
    "# AdamW is an optimizer which is a Adam Optimzier with weight-decay-fix\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                  eps = 1e-8 )\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140,
     "referenced_widgets": [
      "f250c6e44b09489da63445449c3ddb48",
      "ec9fabb1d8db4d399d6abf6cc9c15733",
      "920cdf1bc99c4304abfd3ce136d5ab9a",
      "3e46b8f3838f40258580ef34cce77586",
      "5e0ed5db759747739b3ca82651bf80a9",
      "88095ebe836b4495b0d8fb7016042428",
      "cff71ff4c4874b14bf88ab38b2082791",
      "dd381dd679ec47f5862c5235d8f44e6e",
      "3b4c9b5419d84bb0910dd0dbcb745c66",
      "92c20c0ffdbe403abcdec8148ef6588a",
      "cf865356a26643938ade56f6130c53c1"
     ]
    },
    "id": "Dhy0o1E9r9n3",
    "outputId": "24a559cd-8a4a-48ad-becf-d8d5ac5fd07e"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f250c6e44b09489da63445449c3ddb48"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 15\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 100, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "uIlrUSsR1UDR"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a helper code for accuracy"
   ],
   "metadata": {
    "id": "l-5OUQH81cy8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "metadata": {
    "id": "CN78irbGyEkH"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Train model"
   ],
   "metadata": {
    "id": "Gf0mkkq3UNCF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Let's start the training process\n",
    "\n",
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to\n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 20 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because\n",
    "        # accumulating the gradients is \"convenient while training RNNs\".\n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here:\n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids,\n",
    "                    token_type_ids=None,\n",
    "                    attention_mask=b_input_mask,\n",
    "                    labels=b_labels)\n",
    "\n",
    "        # The call to `model` always returns a tuple, so we need to pull the\n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value\n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        # Add batch to CPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which\n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here:\n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dJ4q1d9-1wgK",
    "outputId": "7b2ec390-4f09-41ff-a16b-343965f8b340"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "======== Epoch 1 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 4.06\n",
      "  Training epoch took: 0:01:00\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.02\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 4.01\n",
      "  Training epoch took: 0:00:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.02\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 3 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 4.01\n",
      "  Training epoch took: 0:00:54\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.00\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 4 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 3.98\n",
      "  Training epoch took: 0:00:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.05\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 5 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 3.94\n",
      "  Training epoch took: 0:00:55\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.05\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 6 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 3.87\n",
      "  Training epoch took: 0:00:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.04\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 7 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 3.75\n",
      "  Training epoch took: 0:00:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.09\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 8 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 3.64\n",
      "  Training epoch took: 0:00:55\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.17\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 9 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 3.52\n",
      "  Training epoch took: 0:00:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.30\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 10 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 3.37\n",
      "  Training epoch took: 0:00:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.32\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 11 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 3.29\n",
      "  Training epoch took: 0:01:00\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.45\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 12 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 3.20\n",
      "  Training epoch took: 0:00:57\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.65\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 13 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 3.10\n",
      "  Training epoch took: 0:00:57\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.73\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 14 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 3.05\n",
      "  Training epoch took: 0:00:58\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.77\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 15 / 15 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 3.01\n",
      "  Training epoch took: 0:00:55\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_path = \"./gdrive/MyDrive/bert_model\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# !cp -r output /gdrive/MyDrive"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "At8VgtfzWkSI",
    "outputId": "e95cfa3e-5833-4d0d-f849-053a5b912da3"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /gdrive\n",
      "cp: cannot stat 'output': No such file or directory\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Load the tokenizer alongside the model (if applicable)\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    logits = p.predictions\n",
    "    labels = p.label_ids\n",
    "    probabilities = softmax(logits, axis=-1)\n",
    "    loss = log_loss(labels.flatten(), probabilities.reshape(-1, probabilities.shape[-1]), labels=[i for i in range(logits.shape[-1])])\n",
    "    perplexity = np.exp(loss)\n",
    "    return {\"perplexity\": perplexity}"
   ],
   "metadata": {
    "id": "wXIQp2fSc1p8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation\n"
   ],
   "metadata": {
    "id": "wvbFu3h2c3BY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sentences = testing_data\n",
    "labels = testing_labels\n",
    "\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN,\n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)\n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ],
   "metadata": {
    "id": "X6ur0ugXdy1T"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Evaluating our model on the test set\n",
    "\n",
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict\n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  # Telling the model not to compute or store gradients, saving memory and\n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None,\n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)"
   ],
   "metadata": {
    "id": "sDzOV6kseBVp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "# put labels into array (they stored in arrays of batches)\n",
    "predslabels = []\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "\n",
    "  # The predictions for this batch are a 2-column ndarray (one column for \"0\"\n",
    "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "  # in to a list of 0s and 1s.\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  preslabels = predslabels.append(pred_labels_i)\n",
    "  # Calculate and store the coef for this batch.\n",
    "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
    "  matthews_set.append(matthews)"
   ],
   "metadata": {
    "id": "M5YRwzBTjERR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "# Calculate the MCC\n",
    "flat_true_labels = np.asarray(flat_true_labels)\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('MCC: %.3f' % mcc)"
   ],
   "metadata": {
    "id": "mtxliWFrfm_K"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "\n",
    "# print(multilabel_confusion_matrix(flat_true_labels, flat_predictions))\n",
    "# print(accuracy_score(flat_true_labels, flat_predictions))\n",
    "\n",
    "print(flat_true_labels)\n",
    "print(flat_predictions)\n",
    "# cm = confusion_matrix(flat_true_labels, flat_predictions)\n",
    "\n",
    "# cm_disp = ConfusionMatrixDisplay(cm, display_labels=clf.classes_)\n",
    "#     # Needs matplotlib installed to run\n",
    "# cm_disp.plot()\n",
    "# plt.show()\n",
    "# cm_disp.plot()"
   ],
   "metadata": {
    "id": "2EL6EstCeKDw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Use model"
   ],
   "metadata": {
    "id": "a8qSoUyGCd_w"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_generation(generated_response):\n",
    "  #Find the position of A in assistant and add 10 characters\n",
    "  assistant_index = generated_response.find(\"Assistant:\") + 10\n",
    "\n",
    "  # Check if 'ASSISTANT:' is found in the text and the text starts with \"Assistant\"\n",
    "  if assistant_index != -1:\n",
    "      # Remove everything before ':', also removes repetition of user input\n",
    "      generated_text = generated_response[assistant_index+1:]\n",
    "      # do recursively until no assistant index is found? if it keeps printing multiple\n",
    "\n",
    "  # given that string 'User:' comes after the desired response\n",
    "  user_index = generated_text.find(\"User:\")\n",
    "  if user_index != -1:\n",
    "      generated_text = generated_text[:user_index]\n",
    "\n",
    "\n",
    "  return generated_text"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "gCqNZHmjSnwO",
    "outputId": "bb3a81cf-e914-4733-8d13-6a2297029840"
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'TESTING COOL BEANS NOT SO COOL. '"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def get_prediction(text,tokenizer,model):\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  # Your text for classification\n",
    "  text = \"What to do if Cuts?\"\n",
    "\n",
    "  # Encode the sentence with special tokens and padding\n",
    "  encoded_dict = tokenizer.encode_plus(\n",
    "      text,\n",
    "      add_special_tokens=True,\n",
    "      max_length=64,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors=\"pt\",\n",
    "  )\n",
    "\n",
    "  # Extract input IDs and attention mask\n",
    "  input_ids = encoded_dict[\"input_ids\"]\n",
    "  attention_mask = encoded_dict[\"attention_mask\"]\n",
    "\n",
    "  # Pass the input through the model\n",
    "  with torch.no_grad():\n",
    "    outputs = model(**{\"input_ids\": input_ids, \"attention_mask\": attention_mask})\n",
    "\n",
    "  # Get logits (prediction scores) for each class\n",
    "  logits = outputs.logits.squeeze(0)  # Remove batch dimension\n",
    "\n",
    "  # Get the predicted class label (argmax)\n",
    "  predicted_class = torch.argmax(logits).item()\n",
    "  pred = [predicted_class]\n",
    "  prediction = label_encoder.inverse_transform(pred)[0]\n",
    "  return prediction\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "Exb97Hxm1ahk",
    "outputId": "47c066fc-605d-48a7-be64-3a26930755ee"
   },
   "execution_count": 90,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Cuts'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 90
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "with open('label_encoder.pkl', 'rb') as file:\n",
    "  try:\n",
    "    # Attempt to load the label encoder\n",
    "    loaded_encoder = pickle.load(file)\n",
    "    print(\"Label encoder loaded successfully!\")\n",
    "  except EOFError:\n",
    "    print(\"Error: Pickle file seems to be empty.\")\n",
    "  except pickle.UnpicklingError as e:\n",
    "    print(\"Error loading pickle file:\", e)\n",
    "\n",
    "# Load the model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert_model\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert_model\")\n",
    "print(get_prediction(user_input,tokenizer,model))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "SSz4ChNb4WTE",
    "outputId": "c8231b7a-eadc-4bea-cbc4-c6209e2e20e0"
   },
   "execution_count": 94,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Label encoder loaded successfully!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Symptoms'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 94
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!cp label_encoder.pkl /gdrive/MyDrive"
   ],
   "metadata": {
    "id": "cs4THbjCBSaG"
   },
   "execution_count": 96,
   "outputs": []
  }
 ]
}
